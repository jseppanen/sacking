
env: gym/Pendulum-v0

policy:
  hidden_layers: [64, 64]

q_network:
  hidden_layers: [64, 64]
  num_heads: 2

batch_size: 128
learning_rate: 0.001
num_steps: 100000
num_initial_exploration_steps: 10000
replay_buffer_size: 100000
target_network_update_weight: 0.005

progress_interval: 1000
checkpoint_interval: 10000
